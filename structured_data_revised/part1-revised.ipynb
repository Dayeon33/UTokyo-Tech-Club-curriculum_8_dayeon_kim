{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8587,"databundleVersionId":868304,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/input\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T10:28:40.705744Z","iopub.execute_input":"2025-09-14T10:28:40.706113Z","iopub.status.idle":"2025-09-14T10:28:40.711393Z","shell.execute_reply.started":"2025-09-14T10:28:40.706088Z","shell.execute_reply":"2025-09-14T10:28:40.710532Z"}},"outputs":[{"name":"stdout","text":"['competitive-data-science-predict-future-sales']\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"data_path = \"/kaggle/input/competitive-data-science-predict-future-sales/\"\nprint(os.listdir(data_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T10:28:40.712820Z","iopub.execute_input":"2025-09-14T10:28:40.713057Z","iopub.status.idle":"2025-09-14T10:28:40.729627Z","shell.execute_reply.started":"2025-09-14T10:28:40.713038Z","shell.execute_reply":"2025-09-14T10:28:40.728511Z"}},"outputs":[{"name":"stdout","text":"['items.csv', 'sample_submission.csv', 'item_categories.csv', 'sales_train.csv', 'shops.csv', 'test.csv']\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndata_path = '/kaggle/input/competitive-data-science-predict-future-sales/'\n\nitems = pd.read_csv(data_path + 'items.csv')\nshops = pd.read_csv(data_path + 'shops.csv')\ncats = pd.read_csv(data_path + 'item_categories.csv')\ntrain = pd.read_csv(data_path + 'sales_train.csv')\ntest  = pd.read_csv(data_path + 'test.csv').set_index('ID')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T10:28:40.730611Z","iopub.execute_input":"2025-09-14T10:28:40.731330Z","iopub.status.idle":"2025-09-14T10:28:42.285052Z","shell.execute_reply.started":"2025-09-14T10:28:40.731305Z","shell.execute_reply":"2025-09-14T10:28:42.284234Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from itertools import product\nfrom sklearn.preprocessing import LabelEncoder\n\n# 이상치 처리\ntrain = train[train.item_price < 100000]\ntrain = train[train.item_cnt_day < 1001]\nmedian = train[\n    (train.shop_id == 32) & (train.item_id == 2973) &\n    (train.date_block_num == 4) & (train.item_price > 0)\n].item_price.median()\ntrain.loc[train.item_price < 0, 'item_price'] = median\n\n# shop_id 보정\ntrain.loc[train.shop_id == 0, 'shop_id'] = 57\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\ntrain.loc[train.shop_id == 10, 'shop_id'] = 11\ntest.loc[test.shop_id == 10, 'shop_id'] = 11\n\n# shop / category 전처리\nshops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад TЦ \"7Я\"'\nshops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\nshops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\nshops['city_code'] = LabelEncoder().fit_transform(shops['city'])\nshops = shops[['shop_id','city_code']]\n\ncats['split'] = cats['item_category_name'].str.split('-')\ncats['type'] = cats['split'].map(lambda x: x[0].strip())\ncats['type_code'] = LabelEncoder().fit_transform(cats['type'])\ncats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\ncats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\ncats = cats[['item_category_id','type_code','subtype_code']]\n\nitems.drop(['item_name'], axis=1, inplace=True)\n\n# 월별 판매량 데이터\nmatrix = []\ncols = ['date_block_num','shop_id','item_id']\nfor i in range(34):\n    sales = train[train.date_block_num==i]\n    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\nmatrix = pd.DataFrame(np.vstack(matrix), columns=cols)\nmatrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\nmatrix['shop_id'] = matrix['shop_id'].astype(np.int8)\nmatrix['item_id'] = matrix['item_id'].astype(np.int16)\nmatrix.sort_values(cols,inplace=True)\n\ntrain['revenue'] = train['item_price'] *  train['item_cnt_day']\ngroup = train.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=cols, how='left')\nmatrix['item_cnt_month'] = (matrix['item_cnt_month'].fillna(0).clip(0,20)).astype(np.float16)\n\n# test 데이터 추가\ntest['date_block_num'] = 34\ntest['date_block_num'] = test['date_block_num'].astype(np.int8)\ntest['shop_id'] = test['shop_id'].astype(np.int8)\ntest['item_id'] = test['item_id'].astype(np.int16)\n\nmatrix = pd.concat([matrix, test], ignore_index=True, sort=False)\nmatrix.fillna(0, inplace=True)\n\n# shop, item, cat 조인\nmatrix = pd.merge(matrix, shops, on=['shop_id'], how='left')\nmatrix = pd.merge(matrix, items, on=['item_id'], how='left')\nmatrix = pd.merge(matrix, cats, on=['item_category_id'], how='left')\nmatrix['city_code'] = matrix['city_code'].astype(np.int8)\nmatrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\nmatrix['type_code'] = matrix['type_code'].astype(np.int8)\nmatrix['subtype_code'] = matrix['subtype_code'].astype(np.int8)\n\n# lag feature 추가\ndef lag_feature(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df\n\nmatrix = lag_feature(matrix, [1,2,3,6,12], 'item_cnt_month')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T10:28:42.286853Z","iopub.execute_input":"2025-09-14T10:28:42.287111Z","iopub.status.idle":"2025-09-14T10:29:34.137683Z","shell.execute_reply.started":"2025-09-14T10:28:42.287090Z","shell.execute_reply":"2025-09-14T10:29:34.136982Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# 데이터 분할 \nX_train = matrix[matrix.date_block_num < 33].drop(['item_cnt_month'], axis=1)\nY_train = matrix[matrix.date_block_num < 33]['item_cnt_month']\n\nX_valid = matrix[matrix.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = matrix[matrix.date_block_num == 33]['item_cnt_month']\n\nX_test = matrix[matrix.date_block_num == 34].drop(['item_cnt_month'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T10:29:34.138473Z","iopub.execute_input":"2025-09-14T10:29:34.138702Z","iopub.status.idle":"2025-09-14T10:29:35.461819Z","shell.execute_reply.started":"2025-09-14T10:29:34.138674Z","shell.execute_reply":"2025-09-14T10:29:35.460663Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"Question 1","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# ============= 課題1: 回帰モデル =============\nmodel = XGBRegressor(\n    n_estimators=1000,\n    max_depth=8,\n    learning_rate=0.03,\n    min_child_weight=300,\n    colsample_bytree=0.8,\n    subsample=0.8,\n    eval_metric=\"rmse\",\n    early_stopping_rounds=10,\n    random_state=42\n)\n\n# 학습 (검증 세트 포함)\nmodel.fit(X_train, Y_train, eval_set=[(X_valid, Y_valid)], verbose=False)\n\n# 검증 RMSE 출력\nY_pred = model.predict(X_valid)\nrmse = mean_squared_error(Y_valid, Y_pred, squared=False)\nprint(\"[課題1] Validation RMSE:\", rmse)\n\n# 테스트 데이터 예측 → CSV 저장\nsubmission = model.predict(X_test)\npd.DataFrame({'ID': X_test.index, 'item_cnt_month': submission}).to_csv('part1_resubmit1.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T10:55:16.312365Z","iopub.execute_input":"2025-09-14T10:55:16.312713Z","iopub.status.idle":"2025-09-14T10:59:21.716218Z","shell.execute_reply.started":"2025-09-14T10:55:16.312679Z","shell.execute_reply":"2025-09-14T10:59:21.715513Z"}},"outputs":[{"name":"stdout","text":"[課題1] Validation RMSE: 0.9281663\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"Question 2","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# ============= 課題2: 分類モデル =============\ndef categorize_sales(x):\n    if x == 0:\n        return 'no_sales'\n    elif x <= 5:\n        return 'low'\n    elif x <= 15:\n        return 'medium'\n    else:\n        return 'high'\n\n# 목적 변수를 카테고리화\nY_train_cls = Y_train.apply(categorize_sales)\nY_valid_cls = Y_valid.apply(categorize_sales)\n\n# 문자열 → 숫자 변환\nle = LabelEncoder()\nY_train_enc = le.fit_transform(Y_train_cls)\nY_valid_enc = le.transform(Y_valid_cls)\n\n# XGBoost 분류 모델 (CPU 전용)\nclf = XGBClassifier(\n    random_state=42,\n    early_stopping_rounds=10\n)\n\nclf.fit(X_train, Y_train_enc, eval_set=[(X_valid, Y_valid_enc)], verbose=False)\n\n# 예측 및 결과\nY_pred_enc = clf.predict(X_valid)\nY_pred_cls = le.inverse_transform(Y_pred_enc)\n\nprint(\"[課題2] 分類モデル 評価結果\")\nprint(classification_report(Y_valid_cls, Y_pred_cls))\nprint(confusion_matrix(Y_valid_cls, Y_pred_cls))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T10:48:21.539018Z","iopub.execute_input":"2025-09-14T10:48:21.539335Z","iopub.status.idle":"2025-09-14T10:53:36.931740Z","shell.execute_reply.started":"2025-09-14T10:48:21.539314Z","shell.execute_reply":"2025-09-14T10:53:36.930949Z"}},"outputs":[{"name":"stdout","text":"[課題2] 分類モデル 評価結果\n              precision    recall  f1-score   support\n\n        high       0.47      0.29      0.36       358\n         low       0.63      0.21      0.32     29869\n      medium       0.45      0.14      0.21      1244\n    no_sales       0.89      0.98      0.94    206701\n\n    accuracy                           0.88    238172\n   macro avg       0.61      0.41      0.46    238172\nweighted avg       0.86      0.88      0.85    238172\n\n[[   104     29     26    199]\n [    35   6299    145  23390]\n [    46    527    173    498]\n [    36   3104     43 203518]]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"Question 3","metadata":{}},{"cell_type":"code","source":"# ============= 課題3: PCA (寄与率を変えて確認) =============\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor\nimport numpy as np\nimport pandas as pd\n\n# lag 특징은 NaN이 많아 PCA 전에 제거 (과제 지시사항)\ndrop_cols = ['item_cnt_month_lag_1', 'item_cnt_month_lag_2',\n             'item_cnt_month_lag_3', 'item_cnt_month_lag_6',\n             'item_cnt_month_lag_12']\n\nX_train_prep = X_train.drop(columns=drop_cols, errors='ignore')\nX_valid_prep = X_valid.drop(columns=drop_cols, errors='ignore')\nX_test_prep  = X_test.drop(columns=drop_cols,  errors='ignore')\n\n# 스케일링\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_prep)\nX_valid_scaled = scaler.transform(X_valid_prep)\nX_test_scaled  = scaler.transform(X_test_prep)\n\n# 여러 寄与率을 시도하면서 가장 성능(RMSE)이 좋은 PCA+모델을 선택\nbest = {\"rmse\": np.inf, \"rate\": None, \"pca\": None, \"model\": None, \"n_comp\": None}\nfor rate in [0.90, 0.95, 0.99]:\n    pca = PCA(n_components=rate)  # 寄与率 기반 주성분 추출\n    X_train_pca = pca.fit_transform(X_train_scaled)\n    X_valid_pca = pca.transform(X_valid_scaled)\n\n    model_pca = XGBRegressor(\n        n_estimators=500,\n        max_depth=6,\n        learning_rate=0.05,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        early_stopping_rounds=10,\n        random_state=42\n    )\n    model_pca.fit(X_train_pca, Y_train, eval_set=[(X_valid_pca, Y_valid)], verbose=False)\n\n    pred_pca = model_pca.predict(X_valid_pca)\n    rmse_pca = mean_squared_error(Y_valid, pred_pca, squared=False)\n    print(f\"[課題3] PCA 寄与率={rate}, 主成分数={X_train_pca.shape[1]}, RMSE={rmse_pca}\")\n\n    if rmse_pca < best[\"rmse\"]:\n        best[\"rmse\"]   = rmse_pca\n        best[\"rate\"]   = rate\n        best[\"pca\"]    = pca\n        best[\"model\"]  = model_pca\n        best[\"n_comp\"] = X_train_pca.shape[1]\n\nprint(f\"[課題3] 最良モデル: 寄与率={best['rate']}, 主成分数={best['n_comp']}, RMSE={best['rmse']}\")\n\n# 테스트 셋을 '베스트 PCA'로 변환 후 예측 → CSV 저장\nX_test_pca = best[\"pca\"].transform(X_test_scaled)\nsubmission_pca = best[\"model\"].predict(X_test_pca)\npd.DataFrame({'ID': X_test.index, 'item_cnt_month': submission_pca}).to_csv('part1_resubmit3.csv', index=False)\nprint(\"Saved part1_resubmit3.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:06:31.199406Z","iopub.execute_input":"2025-09-14T11:06:31.200126Z","iopub.status.idle":"2025-09-14T11:09:31.152132Z","shell.execute_reply.started":"2025-09-14T11:06:31.200094Z","shell.execute_reply":"2025-09-14T11:09:31.151237Z"}},"outputs":[{"name":"stdout","text":"[課題3] PCA 寄与率=0.9, 主成分数=5, RMSE=1.1036396026611328\n[課題3] PCA 寄与率=0.95, 主成分数=5, RMSE=1.1036396026611328\n[課題3] PCA 寄与率=0.99, 主成分数=5, RMSE=1.1036396026611328\n[課題3] 最良モデル: 寄与率=0.9, 主成分数=5, RMSE=1.1036396026611328\nSaved part1_resubmit3.csv\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"Question 4","metadata":{}},{"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# ============= 課題4: クラスタリング (GMMで最適クラスタ数) =============\n\n# 商品情報 확장 (items + cats + 평균 가격)\nitems_extended = pd.merge(items, cats, on='item_category_id', how='left')\naverage_price = train.groupby('item_id')['item_price'].mean().reset_index()\naverage_price.columns = ['item_id', 'average_price']\nitems_extended = pd.merge(items_extended, average_price, on='item_id', how='left')\n\n# 특징: 평균 가격\nfeatures = items_extended[['average_price']]\n\n# 스케일링 + NaN 제거\nscaler = StandardScaler()\nfeatures_scaled = scaler.fit_transform(features.dropna())\n\n# ---------------- K-means ----------------\nkmeans = KMeans(n_clusters=5, n_init=10, random_state=42)\nclusters = kmeans.fit_predict(features_scaled)\nsilhouette_avg = silhouette_score(features_scaled, clusters)\nprint(\"[課題4] K-means 결과\")\nprint(f\"  - silhouette score: {silhouette_avg:.4f}\")\n\n# ---------------- GMM ----------------\nbics, aics = [], []\nfor n in range(1, 11):\n    gmm = GaussianMixture(n_components=n, random_state=42)\n    gmm.fit(features_scaled)\n    bics.append(gmm.bic(features_scaled))\n    aics.append(gmm.aic(features_scaled))\n\nbest_n_bic = np.argmin(bics) + 1\nbest_n_aic = np.argmin(aics) + 1\nprint(\"[課題4] GMM 結果\")\nprint(f\"  - 最適クラスタ数 (BIC): {best_n_bic}\")\nprint(f\"  - 最適クラスタ数 (AIC): {best_n_aic}\")\n\n# 최적 GMM으로 학습\nbest_gmm = GaussianMixture(n_components=best_n_bic, random_state=42)\nclusters_gmm = best_gmm.fit_predict(features_scaled)\n\nitems_extended = items_extended.dropna(subset=['average_price'])\nitems_extended['cluster'] = clusters_gmm\n\nprint(\"[課題4] GMM クラスタごとの平均値 (average_price)\")\nprint(items_extended.groupby('cluster')['average_price'].mean())\n\n# ---------------- 精度改善: 클러스터 feature를 활용한 회귀 모델 ----------------\n\n# item_id - cluster 매핑 테이블 생성\nitem_cluster_map = items_extended[['item_id', 'cluster']].drop_duplicates()\n\n# 학습/검증/테스트 데이터에 cluster 병합\nX_train_cluster = pd.merge(X_train, item_cluster_map, on='item_id', how='left')\nX_valid_cluster = pd.merge(X_valid, item_cluster_map, on='item_id', how='left')\nX_test_cluster  = pd.merge(X_test,  item_cluster_map, on='item_id', how='left')\n\n# 결측치(NaN) 있으면 -1로 채움\nX_train_cluster['cluster'] = X_train_cluster['cluster'].fillna(-1).astype(int)\nX_valid_cluster['cluster'] = X_valid_cluster['cluster'].fillna(-1).astype(int)\nX_test_cluster['cluster']  = X_test_cluster['cluster'].fillna(-1).astype(int)\n\n# 개선된 회귀 모델 학습\nmodel_cluster = XGBRegressor(\n    n_estimators=800,\n    max_depth=6,\n    learning_rate=0.05,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    early_stopping_rounds=10,\n    random_state=42\n)\nmodel_cluster.fit(X_train_cluster, Y_train, eval_set=[(X_valid_cluster, Y_valid)], verbose=False)\n\n# 검증 RMSE 출력\npred_valid_cluster = model_cluster.predict(X_valid_cluster)\nrmse_cluster = mean_squared_error(Y_valid, pred_valid_cluster, squared=False)\nprint(\"[課題4] Validation RMSE (클러스터 feature 포함):\", rmse_cluster)\n\n# ---------------- CSV 저장 ----------------\nsubmission_cluster = model_cluster.predict(X_test_cluster)\npd.DataFrame({'ID': X_test.index, 'item_cnt_month': submission_cluster}).to_csv('part1_resubmit4.csv', index=False)\nprint(\"Saved part1_resubmit4.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:11:31.399830Z","iopub.execute_input":"2025-09-14T11:11:31.400129Z","iopub.status.idle":"2025-09-14T11:14:13.615735Z","shell.execute_reply.started":"2025-09-14T11:11:31.400097Z","shell.execute_reply":"2025-09-14T11:14:13.614627Z"}},"outputs":[{"name":"stdout","text":"[課題4] K-means 결과\n  - silhouette score: 0.7274\n[課題4] GMM 結果\n  - 最適クラスタ数 (BIC): 10\n  - 最適クラスタ数 (AIC): 10\n[課題4] GMM クラスタごとの平均値 (average_price)\ncluster\n0     1558.589708\n1     8522.775558\n2      225.084317\n3    29496.453323\n4     4742.223836\n5     2753.435610\n6    20199.338675\n7    44734.300000\n8      761.589483\n9    12822.564946\nName: average_price, dtype: float64\n[課題4] Validation RMSE (클러스터 feature 포함): 0.9371017\nSaved part1_resubmit4.csv\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"Download csv\n","metadata":{}},{"cell_type":"code","source":"import shutil\n\n# 결과 파일들을 하나로 압축\nshutil.make_archive(\"part1_results\", \"zip\", \"/kaggle/working\")\n\n# 다운로드 링크 출력\nimport IPython.display as disp\ndisp.FileLink(\"part1_results.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:22:09.701528Z","iopub.execute_input":"2025-09-14T11:22:09.701794Z","iopub.status.idle":"2025-09-14T11:22:10.897197Z","shell.execute_reply.started":"2025-09-14T11:22:09.701761Z","shell.execute_reply":"2025-09-14T11:22:10.896387Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/part1_results.zip","text/html":"<a href='part1_results.zip' target='_blank'>part1_results.zip</a><br>"},"metadata":{}}],"execution_count":38}]}