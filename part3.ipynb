{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02ee9bb6-49b1-4ecf-a63f-22efe928de26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL exists?: True | PDF exists?: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3998d5534546409723ac9f39feca50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading PDF:   0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages: 320 | Extracted chunks: 550\n",
      "Loaded docs -> JSONL: 22794 | PDF: 550\n",
      "Done! Results saved.\n",
      "JSON path: data/io_examples_for_pr.json\n",
      "CSV path: data/io_examples_for_pr.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>retrieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize the overview of the My Number system.</td>\n",
       "      <td>[804\\n15,109\\n15,252\\n15,273\\n15,759\\n16,123\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the key points of the Digital Garden ...</td>\n",
       "      <td>[また、5GをはじめとするICTインフラ整備支援策と5G利活用促進\\n策を一体的かつ効果的に...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Briefly explain the security measures for the ...</td>\n",
       "      <td>[soumu.go.jp/main_sosiki/kenkyu/cybersecurity_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If there are KPIs or progress related to local...</td>\n",
       "      <td>[年度情報通信メディアの利用時間と情報行動に関する調査」\\n総務省「令和5 年度 テレワーク...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summarize the status of the spread of online a...</td>\n",
       "      <td>[＊17 European Commission, “The Digital Service...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0    Summarize the overview of the My Number system.   \n",
       "1  What are the key points of the Digital Garden ...   \n",
       "2  Briefly explain the security measures for the ...   \n",
       "3  If there are KPIs or progress related to local...   \n",
       "4  Summarize the status of the spread of online a...   \n",
       "\n",
       "                                           retrieved  \n",
       "0  [804\\n15,109\\n15,252\\n15,273\\n15,759\\n16,123\\n...  \n",
       "1  [また、5GをはじめとするICTインフラ整備支援策と5G利活用促進\\n策を一体的かつ効果的に...  \n",
       "2  [soumu.go.jp/main_sosiki/kenkyu/cybersecurity_...  \n",
       "3  [年度情報通信メディアの利用時間と情報行動に関する調査」\\n総務省「令和5 年度 テレワーク...  \n",
       "4  [＊17 European Commission, “The Digital Service...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, json, pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, Document, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pydantic import PrivateAttr\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 로컬 Hugging Face 임베딩 클래스 정의 (BaseEmbedding 상속 + PrivateAttr 사용)\n",
    "class LocalHFEmbedding(BaseEmbedding):\n",
    "    _model: SentenceTransformer = PrivateAttr()\n",
    "\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._model = SentenceTransformer(model_name)\n",
    "\n",
    "    # 동기 메서드\n",
    "    def _get_query_embedding(self, query: str):\n",
    "        return self._model.encode(query, convert_to_numpy=True).tolist()\n",
    "\n",
    "    def _get_text_embedding(self, text: str):\n",
    "        return self._model.encode(text, convert_to_numpy=True).tolist()\n",
    "\n",
    "    def _get_text_embeddings(self, texts: list[str]):\n",
    "        return [self._get_text_embedding(t) for t in texts]\n",
    "\n",
    "    # 비동기 메서드\n",
    "    async def _aget_query_embedding(self, query: str):\n",
    "        return self._get_query_embedding(query)\n",
    "\n",
    "    async def _aget_text_embedding(self, text: str):\n",
    "        return self._get_text_embedding(text)\n",
    "\n",
    "    async def _aget_text_embeddings(self, texts: list[str]):\n",
    "        return self._get_text_embeddings(texts)\n",
    "\n",
    "# 전역 설정 (로컬 임베딩 사용)\n",
    "Settings.embed_model = LocalHFEmbedding()\n",
    "splitter = SentenceSplitter(chunk_size=1200, chunk_overlap=200)\n",
    "\n",
    "# 데이터 경로\n",
    "DATA_DIR = Path(\"./data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "JSONL_PATH = DATA_DIR / \"JaGovFaqs-22k.jsonl\"\n",
    "PDF_PATH   = Path(\"~/Desktop/00zentai.pdf\").expanduser()  # PDF 저장 경로 확인 필요\n",
    "\n",
    "print(\"JSONL exists?:\", JSONL_PATH.exists(), \"| PDF exists?:\", PDF_PATH.exists())\n",
    "\n",
    "# JSONL 불러오기\n",
    "def load_jsonl_as_documents(jsonl_path: Path):\n",
    "    docs = []\n",
    "    if jsonl_path.exists():\n",
    "        with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                obj = json.loads(line)\n",
    "                q = obj.get(\"question\") or obj.get(\"Q\") or \"\"\n",
    "                a = obj.get(\"answer\")   or obj.get(\"A\") or obj.get(\"answer_text\") or \"\"\n",
    "                text = f\"Q: {q}\\nA: {a}\"\n",
    "                docs.append(Document(text=text))\n",
    "    return docs\n",
    "\n",
    "jsonl_docs = load_jsonl_as_documents(JSONL_PATH)\n",
    "\n",
    "# PDF 불러오기 (PyMuPDF, 진행률 표시)\n",
    "pdf_docs = []\n",
    "if PDF_PATH.exists():\n",
    "    doc = fitz.open(PDF_PATH)\n",
    "    for i, page in enumerate(tqdm(doc, desc=\"Loading PDF\")):\n",
    "        text = page.get_text(\"text\")\n",
    "        if text.strip():\n",
    "            for node in splitter.get_nodes_from_documents([Document(text=text)]):\n",
    "                pdf_docs.append(Document(\n",
    "                    text=node.get_content(),\n",
    "                    metadata={\"source\": f\"soumu_whitepaper_r06_page_{i+1}\"}\n",
    "                ))\n",
    "    print(\"Total pages:\", len(doc), \"| Extracted chunks:\", len(pdf_docs))\n",
    "else:\n",
    "    print(\"PDF file not found:\", PDF_PATH)\n",
    "\n",
    "print(\"Loaded docs -> JSONL:\", len(jsonl_docs), \"| PDF:\", len(pdf_docs))\n",
    "\n",
    "# 인덱스 생성\n",
    "all_docs = jsonl_docs + pdf_docs\n",
    "if not all_docs:\n",
    "    raise RuntimeError(\"No documents to index. Please check data files.\")\n",
    "\n",
    "index = VectorStoreIndex.from_documents(all_docs)\n",
    "retriever = VectorIndexRetriever(index=index, similarity_top_k=3)\n",
    "\n",
    "# 질의 함수 (retrieval 결과 반환)\n",
    "def ask(question: str) -> Dict[str, Any]:\n",
    "    nodes = retriever.retrieve(question)\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"retrieved\": [n.node.get_content()[:200] for n in nodes]  # 앞 200자만 미리보기\n",
    "    }\n",
    "\n",
    "# 과제용 질문 5개 실행\n",
    "questions = [\n",
    "    \"Summarize the overview of the My Number system.\",\n",
    "    \"What are the key points of the Digital Garden City Nation concept in the 2024 White Paper?\",\n",
    "    \"Briefly explain the security measures for the My Number card.\",\n",
    "    \"If there are KPIs or progress related to local government DX, please cite them.\",\n",
    "    \"Summarize the status of the spread of online application procedures based on the White Paper.\",\n",
    "]\n",
    "\n",
    "results = [ask(q) for q in questions]\n",
    "\n",
    "# 결과 저장 + 출력\n",
    "json_path = DATA_DIR / \"io_examples_for_pr.json\"\n",
    "csv_path  = DATA_DIR / \"io_examples_for_pr.csv\"\n",
    "\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "pd.DataFrame(results).to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Done! Results saved.\")\n",
    "print(\"JSON path:\", json_path)\n",
    "print(\"CSV path:\", csv_path)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6ef85-28d1-42ac-a190-d2f79aa55189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
